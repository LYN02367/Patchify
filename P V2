import os
import numpy as np
import rasterio
import pandas as pd
from patchify import patchify
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Dropout
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import save_img
import itertools

def read_multiband_image(image_path):
    with rasterio.open(image_path) as src:
        bands = src.read()
        image = np.moveaxis(bands, 0, -1)
    return image, src.transform

def read_mask(mask_path):
    with rasterio.open(mask_path) as src:
        mask = src.read(1)  # 讀取單通道的遮罩
    return mask

def pad_image(image, patchsize):
    # 取得影像的高度和寬度
    height, width = image.shape[:2]
    
    # 計算需要填充的高度和寬度
    pad_height = (patchsize - height % patchsize) % patchsize
    pad_width = (patchsize - width % patchsize) % patchsize
    
    # 使用零值填充影像
    padded_image = np.pad(image, ((0, pad_height), (0, pad_width), (0, 0)), mode='constant')
    
    return padded_image

def pad_mask(mask, patchsize):
    # 取得遮罩的高度和寬度
    height, width = mask.shape
    
    # 計算需要填充的高度和寬度
    pad_height = (patchsize - height % patchsize) % patchsize
    pad_width = (patchsize - width % patchsize) % patchsize
    
    # 使用零值填充遮罩
    padded_mask = np.pad(mask, ((0, pad_height), (0, pad_width)), mode='constant')
    
    return padded_mask


def process_patches(patches_img, patches_mask):
    X = [ ]
    y = [ ]
    
    for i in range(patches_img.shape[0]):
        for j in range(patches_img.shape[1]):
            patch = patches_img[i, j, 0]
            mask = patches_mask[i, j]
            if mask.ndim > 2:
                mask = mask[..., 0]
            X.append(patch)
            y.append(mask)
    
    return np.array(X), np.array(y)

def build_unet(input_shape):
    input_layer = Input(shape=input_shape)  # 輸入層
    dropoutRate = 0.1  # Dropout 機率

    # 編碼器（Encoder）
    conv1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(input_layer) # 第一層2D卷積層，64個大小為3x3的濾波器，主要學習特徵圖，
    # relu將負數設為0，有助於加快訓練模型速度，輸入影像與輸出影像的大小將保持一致，並在邊界填充零值才能被整除，並生成 64 個新的特徵圖
    conv1 = Dropout(dropoutRate)(conv1)
    conv1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(conv1)
    # 最大池化層，將影像尺寸縮小一半，並減少運算量，同時保留最重要的特徵。這有助於防止過擬合並加速模型的訓練。
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) 

    conv2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(pool1)
    conv2 = Dropout(dropoutRate)(conv2)
    conv2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(pool2)
    conv3 = Dropout(dropoutRate)(conv3)
    conv3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(128, (3, 3), activation='relu',kernel_initializer='RandomNormal', padding='same')(pool3)
    conv4 = Dropout(dropoutRate)(conv4)
    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    
    # 橋接層（Bridge）：連接編碼器與解碼器，負責處理影像尺寸的變化和提取更高層次的特徵
    conv5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(pool4)
    conv5 = Dropout(dropoutRate)(conv5)
    conv5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(conv5)

    # 解碼器（Decoder）：恢復影像尺寸並進行特徵重建
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5) # 上採樣層，將尺寸放大，輸出尺寸需與預期相符，避免尺寸有邊界問題
    u6 = Concatenate()([u6, conv4])  # 跳躍連接：將編碼器層與解碼器層的特徵圖合併，幫助解碼器更好地恢復影像的細節
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(u6)
    c6 = Dropout(dropoutRate)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu',kernel_initializer='RandomNormal', padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = Concatenate()([u7, conv3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(u7)
    c7 = Dropout(dropoutRate)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = Concatenate()([u8, conv2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(u8)
    c8 = Dropout(dropoutRate)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = Concatenate()([u9, conv1])
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(u9)
    c9 = Dropout(dropoutRate)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='RandomNormal',padding='same')(c9)

    # 輸出層：生成最終的分割結果，單通道，使用sigmoid激活進行二分類
    output_layer = Conv2D(1, (1, 1), activation='sigmoid')(c9)

    # 建立模型
    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
    # 輸出模型結構摘要
    # model.summary()

    return model

def save_prediction_with_visualization(image, mask, prediction, save_path):
    # 視覺化處理
    plt.figure(figsize=(12, 4))
    # 原始影像
    plt.subplot(1, 3, 1)
    img_display = image[..., :3]
    img_display = (img_display - np.min(img_display)) / (np.max(img_display) - np.min(img_display))  # 正規化顯示
    plt.imshow(img_display)
    plt.title("Original")

    # 遮罩影像
    plt.subplot(1, 3, 2)
    plt.imshow(mask, cmap="gray")
    plt.title("Validation")

    # 預測影像
    plt.subplot(1, 3, 3)
    plt.imshow(prediction, cmap="gray")  # 設定閾值來顯示預測結果
    plt.title("Prediction")

    # 儲存圖像
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

    # 確認保存成功
    print(f"Visualization saved to {save_path}")

def main():
    patchsize = 32  # 定義補丁大小
    step = patchsize  # 步長設為補丁大小
    pre_collapse_folder = r"E:\NTOU\meeting\pre_collapse_images"
    post_collapse_folder = r"E:\NTOU\meeting\post_collapse_images"
    validation_folder = r"E:\NTOU\meeting\validation_images"
    output_folder = r"E:\NTOU\meeting\CNN\visualization_results"  # 輸出預測結果的資料夾
    
    # 檢查是否存在輸出資料夾
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    label_files = [f for f in os.listdir(validation_folder) if f.endswith(".tif") and "label" in f]
    print(f"Label files: {label_files}")

    X_all = []
    y_all = []

    # 用來計算每個檔案被處理的次數
    process_count = {}

    # 使用 itertools.product 創建所有的組合 (災前影像, 災後影像, 標籤檔案)
    image_combinations = itertools.product(os.listdir(pre_collapse_folder), os.listdir(post_collapse_folder), label_files)

    # 記錄已處理過的影像組合，防止重複處理
    processed_image_pairs = set()

    for img_file_pre, img_file_post, label_file in image_combinations:
        img_path_pre = os.path.join(pre_collapse_folder, img_file_pre)
        img_path_post = os.path.join(post_collapse_folder, img_file_post)
        label_path = os.path.join(validation_folder, label_file)

        # 用來避免重複處理影像組合
        img_pair = (img_file_pre, img_file_post)
        if img_pair in processed_image_pairs:
            continue  # 如果這對影像已處理過，就跳過

        # 記錄已處理過的影像組合
        processed_image_pairs.add(img_pair)

        # 統計處理次數
        key = (img_file_pre, img_file_post, label_file)
        process_count[key] = process_count.get(key, 0) + 1

        # 輸出統計結果
        if process_count[key] == 1:  # 每組影像和標籤檔案只處理一次
            print(f"Processing: {img_file_pre}, {img_file_post} with label: {label_file}")

            # 讀取影像和遮罩
            image_pre, _ = read_multiband_image(img_path_pre)
            image_post, _ = read_multiband_image(img_path_post)
            mask = read_mask(label_path)
            print("填充前災前影像尺寸：",image_pre.shape)
            print("填充前災後影像尺寸：",image_post.shape)
            print("填充前驗證樣本尺寸：",mask.shape)
            print("Pre-collapse image range:", image_pre.min(), image_pre.max())
            print("Post-collapse image range:", image_post.min(), image_post.max())


            # 填充影像和遮罩
            image_pre_padded = pad_image(image_pre, patchsize)
            mask_padded = pad_mask(mask, patchsize)  # 無需額外擴展維度
            print("填充後災前影像尺寸：",image_pre_padded.shape)
            print("填充後驗證樣本尺寸：",mask_padded.shape)

            # 切割補丁
            patches_img = patchify(image_pre_padded, (patchsize, patchsize, image_pre_padded.shape[-1]), step=step)
            patches_mask = patchify(mask_padded, (patchsize, patchsize), step=step)

            # 處理補丁並收集樣本
            X, y = process_patches(patches_img, patches_mask)
            X_all.extend(X)
            y_all.extend(y)

    # 轉換為 NumPy 陣列
    X_all = np.array(X_all)
    y_all = np.array(y_all)

    if y_all.ndim == 3:
        y_all = np.expand_dims(y_all, axis=-1)

    # 訓練集、驗證集、測試集劃分
    if len(X_all) > 0 and len(y_all) > 0:
        # 先劃分出測試集
        X_train_val, X_test, y_train_val, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=0)
        # 再從剩下的數據中劃分訓練集和驗證集
        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)

    # 建立和訓練模型
    input_shape = (patchsize, patchsize, X_train.shape[-1])
    model = build_unet(input_shape)
    model.summary()
    
    # 訓練模型
    history = model.fit(X_train, y_train, 
                        epochs=20, 
                        batch_size=8, 
                        validation_data=(X_val, y_val),
                        verbose=2)

    # 使用驗證集來進行預測（也可以使用測試集來進行預測）
    y_pred = model.predict(X_val)
    # 假設模型的預測結果是 'prediction'
    prediction = (y_pred > 0.2).astype(np.uint8)

    # 列印預測結果的最小值和最大值
    print("Prediction min:", np.min(y_pred))
    print("Prediction max:", np.max(y_pred))
    print("Prediction mean:", np.mean(y_pred))

    # 使用測試集來評估模型
    _, acc = model.evaluate(X_test, y_test)
    print("Test Accuracy is = ", (acc * 100.0), "%")

    # 繪製訓練過程中的損失和準確度曲線
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    df_history = pd.DataFrame({'loss': loss, 'val_loss': val_loss, 'acc': acc, 'val_acc': val_acc})
    epochs = range(1, len(loss) + 1)

    # 損失曲線
    plt.rcParams.update(plt.rcParamsDefault)
    plt.plot(epochs, loss, 'o-', label='Training', markersize=5, color='#4f6b8d')  # 'o-' adds a circle marker
    plt.plot(epochs, val_loss, 'o-', label='Validation', markersize=5, color='#cf3832')  # 'o-' adds a circle marker
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(fontsize='large')  # Set the legend font size to large
    plt.grid(linestyle='--')
    plt.tight_layout(pad=1.0)
    plt.show()

    # 準確度曲線
    plt.plot(epochs, acc, 'o-', label='Training', markersize=5, color='#4f6b8d')  # 'o-' adds a circle marker
    plt.plot(epochs, val_acc, 'o-', label='Validation', markersize=5, color='#cf3832')  # 'o-' adds a circle marker
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend(fontsize='large')  # Set the legend font size to large
    plt.grid(linestyle='--')
    plt.tight_layout(pad=1.0)
    plt.show()

    # 檢查預測值的分佈
    plt.hist(y_pred.flatten(), bins=50, alpha=0.75)
    plt.title("Prediction Value Distribution")
    plt.xlabel("Prediction Value")
    plt.ylabel("Frequency")
    plt.show()

    # 儲存所有預測結果
    for i in range(y_pred.shape[0]):
        save_path = os.path.join(output_folder, f"prediction_{i+1}.png")
        save_prediction_with_visualization(X_val[i], y_val[i, ..., 0], y_pred[i, ..., 0], save_path)

if __name__ == "__main__":
    main()
